ROT <- c(0,50)
NIR <- c(0,50)
plot(ROT, NIR, color="white")
plot(ROT, NIR, col="white")
require(autopls)
install.packages("autopls")
install.packages("autopls")
require(autopls)
load(iris)
iris
autopls(iris$Sepal.Length ~ iris$Sepal.Width + iris$Petal.Length + iris$Petal.Width)
autopls(iris$Sepal.Length ~ iris[,2:4])
ref <- iris$Sepal.Length
preds <- iris[,2:4]
test <- autopls(ref ~ preds)
?autopls
## load predictor and response data to the current environment
data (murnau.X)
data (murnau.Y)
## call autopls with the standard options
model <- autopls (murnau.Y ~ murnau.X)
plot(murnau.Y, model$fitted.values)
plot(model)
plot(model, plab=T)
murnau.Y
1+1
1+1
# Example data
square <- t(replicate(50, {
o <- runif(2)
c(o, o + c(0, 0.1), o + 0.1, o + c(0.1, 0), o)
}))
square
square <- read.table("D:/ESDL_grid/grid_coords.txt", sep=",")
square <- read.table("D:/ESDL_grid/grid_coords.txt", sep=",")
square
square <- read.table("D:/ESDL_grid/grid_coords.txt", sep=",", header=T)
ID <- paste0('sq', seq_len(nrow(square)))
# Create SP
polys <- SpatialPolygons(mapply(function(poly, id) {
xy <- matrix(poly, ncol=2, byrow=TRUE)
Polygons(list(Polygon(xy)), ID=id)
}, split(square, row(square)), ID))
require(rgdal)
# create ID for dataframe of polygons
ID <- paste0('sq', seq_len(nrow(gridcells)))
# load data created in ESDL environment/JULIA
gridcells <- read.table("D:/ESDL_grid/grid_coords.txt", sep=",", header=T)
# create ID for dataframe of polygons
ID <- paste0('sq', seq_len(nrow(gridcells)))
ID
# create ID for dataframe of polygons
ID <- paste0('cell', seq_len(nrow(gridcells)))
# Create SP
polys <- SpatialPolygons(mapply(function(poly, id) {
xy <- matrix(poly, ncol=2, byrow=TRUE)
Polygons(list(Polygon(xy)), ID=id)
}, split(gridcells, row(gridcells)), ID))
head(gridcells)
tail(gridcells)
# Example data
square <- t(replicate(50, {
o <- runif(2)
c(o, o + c(0, 0.1), o + 0.1, o + c(0.1, 0), o)
}))
ID <- paste0('sq', seq_len(nrow(square)))
# Create SP
polys <- SpatialPolygons(mapply(function(poly, id) {
xy <- matrix(poly, ncol=2, byrow=TRUE)
Polygons(list(Polygon(xy)), ID=id)
}, split(square, row(square)), ID))
# Create SPDF
polys.df <- SpatialPolygonsDataFrame(polys, data.frame(id=ID, row.names=ID))
plot(polys.df, col=rainbow(50, alpha=0.5))
square
head(square)
# load data created in ESDL environment/JULIA
gridcells <- read.table("D:/ESDL_grid/grid_coords.txt", sep=",", header=T)
head(gridcells)
# load data created in ESDL environment/JULIA
gridcells <- as.matrix(read.table("D:/ESDL_grid/grid_coords.txt", sep=",", header=T))
# create ID for dataframe of polygons
ID <- paste0('cell', seq_len(nrow(gridcells)))
# Create SP
polys <- SpatialPolygons(mapply(function(poly, id) {
xy <- matrix(poly, ncol=2, byrow=TRUE)
Polygons(list(Polygon(xy)), ID=id)
}, split(gridcells, row(gridcells)), ID))
# Create SPDF
polys.df <- SpatialPolygonsDataFrame(polys, data.frame(id=ID, row.names=ID))
writeOGR(polys.df, '.', 'esdl_grid', 'ESRI Shapefile')
ydum <- meanvals+sd
# lets assume the mean error or correlation values are:
meanvals <- c(23, 25, 29, 30)
# and the corresponding sd values are
sd <- c(6, 4, 7, 5)
# then we draw the polygon like this
x <- c(1, 2, 3, 4, 4, 3, 2, 1)
ydum <- meanvals+sd
ydum2 <- meanvals-sd
y <- c(ydum, ydum2)
inv(ydum2)
y <- c(ydum, rev(ydum2))
y
polygon(x,y)
plot(meanvals, col="white")
polygon(x,y)
plot(meanvals, col="white", xlim=c(0,5), ylim=c(0,35))
polygon(x,y)
plot(meanvals, col="white", xlim=c(1,5), ylim=c(0,35))
plot(1:4, meanvals)
polygon(x,y)
plot(meanvals, col="white", xlim=c(1,5), ylim=c(0,35))
plot(1:4, meanvals, xlim=c(1,5), ylim=c(0,35))
polygon(x,y, col="blue",alpha=0.3)
plot(1:4, meanvals, xlim=c(1,5), ylim=c(0,35))
plot(meanvals, col="white", xlim=c(1,5), ylim=c(0,35))
polygon(x,y, col="blue", alpha=0.3)
par(new=T)
plot(1:4, meanvals, xlim=c(1,5), ylim=c(0,35))
plot(meanvals, col="white", xlim=c(1,5), ylim=c(0,35))
polygon(x,y, col=rgb(1, 0, 0,0.5))
par(new=T)
plot(1:4, meanvals, xlim=c(1,5), ylim=c(0,35))
# define fix values
n <- 16
minval <- 0.5
maxval <- 1
mat <- sapply(seq(minval, maxval, length.out = n/2),
function(maxval, minval) c(seq(minval, maxval, length.out = n/2),
seq(maxval, minval, length.out = n/2)),
minval)
mat
## Functions
.get_spatial_response_modis <- function()
{
# define fix values
n <- 16
minval <- 0.5
maxval <- 1
mat <- sapply(seq(minval, maxval, length.out = n/2),
function(maxval, minval) c(seq(minval, maxval, length.out = n/2),
seq(maxval, minval, length.out = n/2)),
minval)
return(matrix(c(mat, mat[length(mat):1]), ncol = 16, nrow = 16))
}
plot(mat)
plot(raster(mat))
require(raster)
plot(raster(mat))
# plot spectral response function of MODIS
plot(raster(matrix(c(mat, mat[length(mat):1]), ncol = 16, nrow = 16)))
?rnorm
?runif
runif(10, min = 0, max = 1)
plot(seq(1,10,1), runif(10, min = 0, max = 1))
plot(seq(1,10,1), runif(10, min = 0, max = 1))
plot(seq(1,10,1), runif(10, min = 0, max = 1))
plot(seq(1,10,1), sort(runif(10, min = 0, max = 1)))
plot(seq(1,10,1), sort(runif(10, min = 0, max = 1)))
plot(seq(1,10,1), sort(runif(10, min = 0, max = 1)))
plot(seq(1,10,1), sort(runif(10, min = 0, max = 1)))
plot(seq(1,10,1), sort(runif(10, min = 0, max = 1)))
sim_refl <- function(n, mean, sd, lower, upper, recall = TRUE)
{
refl <- rnorm(n, mean = mean, sd = sd)
if (recall)
{
refl_out <- !(refl>=lower & refl<=upper)
n_out <- sum(refl_out)
#print(c(n_out, n, sum(refl_out)))
# strange that within the definition of the function, the same function is used?
while (n_out > 0)
{
refl[refl_out] <- sim_refl(n_out, mean, sd, lower, upper,
recall = FALSE)
refl_out <- !(refl>=lower & refl<=upper)
n_out <- sum(refl_out)
}
}
return(refl)
}
require(oneClass)
require(devtools)
install_github("benmack/oneClass")
require(oneClass)
set.seed(25)
pa <- seq(1,25,1)
ran1 <- sample(25,pa, replace = F)
ran1
ran1 <- sample(pa, 25, replace = F)
ran2 <- sample(pa, 25, replace = F)
set.seed(25)
pa <- seq(1,25,1)
ran1 <- sample(pa, 25, replace = F)
ran2 <- sample(pa, 25, replace = F)
set.seed(25)
pa <- seq(1,25,1)
ran1 <- sample(pa, 25, replace = F)
ran2 <- sample(pa, 25, replace = F)
ran1
ran2
ran1
require(velox)
v1 <- c(5,9,8,3,7,1,2,3,2,3,4)
v2 <- c(9,6,7,8,5,9,8,7,3,2,1)
sd(v1)
sd(v2)
mean(s1,s2)
s1 <- sd(v1)
s2 <- sd(v2)
mean(s1,s2)
s1
s2
mean(s1,s2)
mean(c(s1,s2))
sd(c(v1,v2))
2^20
sample(seq(1,3,1), 3)
sample(seq(1,3,1), 3)
sample(seq(1,3,1), 3)
sample(seq(1,3,1), 3)
sample(seq(1,3,1), 3)
authors <- c("Javier Lopatin", "Lucas Rivero", "Andres Ceballos-Comisso")
authors <- c("Javier Lopatin", "Lucas Rivero", "Andres Ceballos-Comisso")
set.seed(25081983)
s <- sample(seq(1,3,1), 3)
autors[s]
authors[s]
## Javier Lopatin = 1
## Lucas Rivero = 2
## Andres Ceballos-Comisso = 3
authors <- c("Javier Lopatin", "Lucas Rivero", "Andres Ceballos-Comisso")
set.seed(25081983)
s <- sample(seq(1,3,1), 3)
authors[s]
install.packages("DHARMa")
require(DHARMa)
set.seed(234234)
sample(seq(1,3,1),1)
set.seed(234234)
sample(seq(1,3,1),1)
set.seed(234234)
sample(seq(1,3,1),1)
set.seed(98734)
sample(seq(1,2,1),1)
set.seed(5298435)
sample(seq(1,2,1),1)
set.seed(3368905)
sample(seq(1,7,1),1)
set.seed(992654)
sample(seq(1,2,1),1)
set.seed(39573)
sample(seq(1,2,1),1)
ref <- c(969.9963, 1486.265, 1696.851,  2106.749, 2566.144,  2774.916,  2883.33, 2979.941, 3395.13, 2652.127)
plot(seq(1,10,1), ref)
seq(6000,18000,1200)
seq(6000,18000,3600)
b1 <- c(25.2,22.4,22.6)
b2 <- c(26.0, 18.9, 21.7)
cor(b1,b2)
cor(b1,b2)^2
# Load data
ay.path<-system.file("extdata/HS_aysen",package="npphen")
ayrasters<-list.files(path=ay.path, pattern=glob2rx("aysen*.tif"), full.names=TRUE)
Aysen_rasters<-stack(ayrasters)
ay_dates<-read.csv(system.file("extdata/date_tables/Aysen_dates.csv", package="npphen"))
Aysen_dates <- as.Date(ay_dates$date, format='%d/%m/%Y')
# Generate a Raster time series using a raster stack and a date database from Aysen
ay_ts<-rts(Aysen_rasters,Aysen_dates)
# Obtain data from a particular pixel generating a time series
ay_pixel<-cellFromXY(ay_ts,c(228373,4806975))
ay_pixelts<-extract(ay_ts,ay_pixel)
plot(ay_pixelts)
# Anomaly for the period [309:331], reference period [1:354]. In this case, ref and anop overlaps
PhenAnoma(x=as.vector(ay_pixelts),dates=Aysen_dates,h=2,refp=c(1:354),
anop=c(309:331), rge=c(0,10000))
library(rts)
library(lubridate)
# Load data
ay.path<-system.file("extdata/HS_aysen",package="npphen")
ayrasters<-list.files(path=ay.path, pattern=glob2rx("aysen*.tif"), full.names=TRUE)
Aysen_rasters<-stack(ayrasters)
ay_dates<-read.csv(system.file("extdata/date_tables/Aysen_dates.csv", package="npphen"))
Aysen_dates <- as.Date(ay_dates$date, format='%d/%m/%Y')
# Generate a Raster time series using a raster stack and a date database from Aysen
ay_ts<-rts(Aysen_rasters,Aysen_dates)
# Obtain data from a particular pixel generating a time series
ay_pixel<-cellFromXY(ay_ts,c(228373,4806975))
ay_pixelts<-extract(ay_ts,ay_pixel)
plot(ay_pixelts)
# Anomaly for the period [309:331], reference period [1:354]. In this case, ref and anop overlaps
PhenAnoma(x=as.vector(ay_pixelts),dates=Aysen_dates,h=2,refp=c(1:354),
anop=c(309:331), rge=c(0,10000))
library(npphen)
# Anomaly for the period [309:331], reference period [1:354]. In this case, ref and anop overlaps
PhenAnoma(x=as.vector(ay_pixelts),dates=Aysen_dates,h=2,refp=c(1:354),
anop=c(309:331), rge=c(0,10000))
aggregate.daily.to.weekly <- function(daily.ts) {
dates      <- as.Date(date_decimal(as.numeric(time(daily.ts))))
xts.daily  <- xts(daily.ts, order.by = dates)
xts.weekly <- round(xts::apply.weekly(xts.daily, median),0)  # xts
start(xts.weekly)
ts.weekly <- ts(data = xts.weekly,
# define the start and end (Year, Week)
start = c(as.numeric(format(start(xts.weekly), "%Y")),
as.numeric(format(start(xts.weekly), "%W"))),
end   = c(as.numeric(format(end(xts.weekly), "%Y")),
as.numeric(format(end(xts.weekly), "%W"))),
frequency = 52)
return(ts.weekly)
}
# load required packages
require(raster)
#require(xts)
require(zoo)
require(bfastSpatial)
require(bfast)
# set working directory
setwd("D:/Multiskalige_FE/5_Practicals/Tag_8_bfast")
# load MODIS time series with images from 2000-2020
mod_ndvi <- brick("MODIS_all_00_20_sm.tif")
# MODIS
m_dat <- read.table("dates_mod.txt")
m_dat_fin <- m_dat[seq(2, nrow(m_dat),2),]
m_dat_fin2 <- as.character(m_dat_fin)
m_dat_for <- as.Date(m_dat_fin2, format = c("%Y%m%d"))
# MODIS (here, row 1, column 1)
m_ts <- as.vector(mod_ndvi[3,32])
m_ts[m_ts==0] <- NA
# prepare dataframe with NDVI values and dates
m.df <- data.frame(m_ts, m_dat_for)
mod_ts <- bfastts(as.vector(m_ts), m_dat_for, type = c("irregular"))
mod_ts_ip <- round(na.approx(mod_ts),0)
plot(mod_ts_ip)
mod_ts_ip2 <- aggregate.daily.to.weekly(mod_ts_ip)
require(xts)
mod_ts_ip2 <- aggregate.daily.to.weekly(mod_ts_ip)
require(lubridate)
mod_ts_ip2 <- aggregate.daily.to.weekly(mod_ts_ip)
aggregate.daily.to.weekly <- function(daily.ts) {
dates      <- as.Date(date_decimal(as.numeric(time(daily.ts))))
xts.daily  <- xts(daily.ts, order.by = dates)
xts.weekly <- round(xts::apply.weekly(xts.daily, median),0)  # xts
start(xts.weekly)
ts.weekly <- ts(data = xts.weekly,
# define the start and end (Year, Week)
start = c(as.numeric(format(start(xts.weekly), "%Y")),
as.numeric(format(start(xts.weekly), "%W"))),
end   = c(as.numeric(format(end(xts.weekly), "%Y")),
as.numeric(format(end(xts.weekly), "%W"))),
frequency = 52)
return(ts.weekly)
}
###
# load raster-stacks exported from the Google Earth Engine
###
# set working directory
setwd("D:/Multiskalige_FE/5_Practicals/Tag_8_bfast")
# load MODIS time series with images from 2000-2020
mod_ndvi <- brick("MODIS_all_00_20_sm.tif")
###
# load corresponding dates of the time series
###
# MODIS
m_dat <- read.table("dates_mod.txt")
m_dat_fin <- m_dat[seq(2, nrow(m_dat),2),]
m_dat_fin2 <- as.character(m_dat_fin)
m_dat_for <- as.Date(m_dat_fin2, format = c("%Y%m%d"))
# MODIS (here, row 1, column 1)
m_ts <- as.vector(mod_ndvi[3,32])
m_ts[m_ts==0] <- NA
mod_ts
# create daily time series object
mod_ts <- bfastts(as.vector(m_ts), m_dat_for, type = c("irregular"))
mod_ts
# interpolate time series
mod_ts_ip <- round(na.approx(mod_ts),0)
# plot the resulting time series
plot(mod_ts_ip)
mod_ts_ip2 <- aggregate.daily.to.weekly(mod_ts_ip)
bfm2 <- bfast(mod_ts_ip2[,1], h = 10/length(mod_ts_ip2[,1]),
season = "harmonic", breaks = 2, max.iter = 2)
plot(bfm2)
bfm2$Magnitude
bfm2$Time
mod_ts_ip2[605]
time(mod_ts_ip2)[605]
as.yearmon(time(mod_ts_ip2)[605])
as.yearmon(time(mod_ts_ip2)[bfm2$Time])
plot(mod_ndvi[[1]])
plot(mod_ndvi[[2]])
plot(mod_ndvi[[5]])
mod_ndvi2 <- aggregate(mod_ndvi,10)
plot(mod_ndvi2[[5]])
plot(mod_ndvi[[5]])
plot(mod_ndvi[[5]], zlim=c(0,3000))
plot(mod_ndvi2[[5]], zlim=c(0,3000))
bfmRaster = function(pixels){
pixels[pixels==0] <- NA
day_ts <- bfastts(as.vector(pixels), dat_hard, type = c("irregular"))
day_ts_ip <- round(na.approx(day_ts),0)
week_ts_ip <- aggregate.daily.to.weekly(day_ts_ip)
bfm_f <- bfast(week_ts_ip[,1], h = 10/length(week_ts_ip[,1]),
season = "harmonic", breaks = 2, max.iter = 2)
return(c(bfm_f$Magnitude, bfm_f$Time))
}
test2 <- calc(mod_ndvi2, function(x){bfmRaster2(x, dat_hard = m_dat_for)})
bfmRaster2 = function(pixels, dat_hard){
pixels[pixels==0] <- NA
day_ts <- bfastts(as.vector(pixels), dat_hard, type = c("irregular"))
day_ts_ip <- round(na.approx(day_ts),0)
week_ts_ip <- aggregate.daily.to.weekly(day_ts_ip)
bfm_f <- bfast(week_ts_ip[,1], h = 10/length(week_ts_ip[,1]),
season = "harmonic", breaks = 2, max.iter = 2)
return(c(bfm_f$Magnitude, bfm_f$Time))
}
test2 <- calc(mod_ndvi2, function(x){bfmRaster2(x, dat_hard = m_dat_for)})
bfras <- calc(mod_ndvi2, function(x){bfmRaster2(x, dat_hard = m_dat_for)})
plot(bfras)
names(bfras) <- c("Magnitude", "Timepoints")
plot(bfras)
aggregate.daily.to.weekly <- function(daily.ts) {
dates      <- as.Date(date_decimal(as.numeric(time(daily.ts))))
xts.daily  <- xts(daily.ts, order.by = dates)
xts.weekly <- round(xts::apply.weekly(xts.daily, median),0)  # xts
start(xts.weekly)
ts.weekly <- ts(data = xts.weekly,
# define the start and end (Year, Week)
start = c(as.numeric(format(start(xts.weekly), "%Y")),
as.numeric(format(start(xts.weekly), "%W"))),
end   = c(as.numeric(format(end(xts.weekly), "%Y")),
as.numeric(format(end(xts.weekly), "%W"))),
frequency = 52)
return(ts.weekly)
}
# load required packages
require(raster)
require(xts)
require(zoo)
require(bfastSpatial)
#require(bfast)
library(rgdal)
library(npphen)
library(rts)
# set working directory
setwd("D:/Multiskalige_FE/5_Practicals/1_GEE_basics_v2")
# load MODIS time series with images from 2000-2020
mod_ndvi <- brick("MODIS_all_00_20_sm.tif")
###
# load corresponding dates of the time series
###
# MODIS
m_dat <- read.table("dates_mod.txt")
m_dat_fin <- m_dat[seq(2, nrow(m_dat),2),]
m_dat_fin2 <- as.character(m_dat_fin)
m_dat_for <- as.Date(m_dat_fin2, format = c("%Y%m%d"))
# MODIS (here, row 1, column 1)
m_ts <- as.vector(mod_ndvi[3,32])
m_ts[m_ts==0] <- NA
###
# create time series objects by merging the NDVI time series values with the corresponding dates
###
# prepare dataframe with NDVI values and dates
m.df <- data.frame(m_ts, m_dat_for)
mod_ts <- bfastts(as.vector(m_ts), m_dat_for, type = c("irregular"))
mod_ts_ip <- round(na.approx(mod_ts),0)
plot(mod_ts_ip)
mod_ts_ip2 <- aggregate.daily.to.weekly(mod_ts_ip)
library(lubridate)
mts <- as.numeric(time(mod_ts_ip))
## 'POSIXct, POSIXt' object
tms <- date_decimal(mts)
evi.num <- as.vector(mod_ts_ip2[,1])
#-------------------------------------------------------------------------
# A. Phen function for phenological reconstruction (for a numerical vector)
phen_1pix <- Phen(evi.num, tms, h=1, rge=c(0,10000), nGS = 23)
mts <- as.numeric(time(mod_ts_ip2))
## 'POSIXct, POSIXt' object
tms <- date_decimal(mts)
evi.num <- as.vector(mod_ts_ip2[,1])
#-------------------------------------------------------------------------
# A. Phen function for phenological reconstruction (for a numerical vector)
phen_1pix <- Phen(evi.num, tms, h=1, rge=c(0,10000), nGS = 23)
plot(phen_1pix)
#-------------------------------------------------------------------------
# B. PhenKplot to see the kernel density of the reconstructed phenology (for a numerical vector)
PhenKplot(evi.num, tms,h=1,nGS=23, xlab="Day of the growing season",ylab="EVI", rge=c(0,10000))
1048/23
1048/22
1048/24
1048/25
1048/26
